\documentclass[11pt,psfig]{article}
\usepackage{epsfig}
\usepackage{times}
\usepackage{amssymb}
\usepackage{float}
\usepackage{listings}

\newcount\refno\refno=1
\def\ref{\the\refno \global\advance\refno by 1}
\def\ux{\underline{x}}
\def\uw{\underline{w}}
\def\bw{\underline{w}}
\def\ut{\underline{\theta}}
\def\umu{\underline{\mu}} 
\def\bmu{\underline{\mu}} 
\def\be{p_e^*}
\newcount\eqnumber\eqnumber=1
\def\eq{\the \eqnumber \global\advance\eqnumber by 1}
\def\eqs{\eq}
\def\eqn{\eqno(\eq)}

 \pagestyle{empty}
\def\baselinestretch{1.1}
\topmargin1in \headsep0.3in
\topmargin0in \oddsidemargin0in \textwidth6.5in \textheight8.5in
\begin{document}
\setlength{\parskip}{1.2ex plus0.3ex minus 0.3ex}


\thispagestyle{empty} \pagestyle{myheadings} \markright{Homework
1: CS 217 Spring 2015}



\title{CS 217 Homework 1}
\author{Zachary DeStefano, 15247592}
\date{Due Date: April 16, 2015}

\maketitle

\vfill\eject

\newpage

\section*{Problem 1}

Using our assumptions about lenses, we have the following diagram:

\begin{figure}[H]
\centering
\includegraphics[height=4in]{hw1prob1diagram.png}
\caption{Diagram of lens and its focal length}
\end{figure}

The left side of the lens gives us the following equation using similar triangles
\[
\frac{y}{f} = \frac{y+y'}{D'}
\]
The right side of the length gives us the following equation using similar triangles
\[
\frac{y'}{f} = \frac{y+y'}{D}
\]
Adding together the two equations, we get the following
\[
\frac{1}{f} (y + y') = (\frac{1}{D} + \frac{1}{D'})(y + y')
\]
Cancelling the term $y+y'$ we end up with
\[
\frac{1}{f} = \frac{1}{D} + \frac{1}{D'}
\]
This is the thin lens equation


\section{Problem 2}

\subsection{Part 1}

The following diagram illustrates the cross-section showing the horizontal and vertical field of view along with the focal length. The field of view will be $2\theta$

\begin{figure}[H]
\centering
\includegraphics[height=4in]{hw1prob2drawing1.png}
\caption{Diagram of focal length and horizontal/vertical field of view}
\end{figure}

Using trigonometry, it is easily observed that
\[
\theta = arctan(\frac{x}{20f})
\]
\newpage
For the horizontal field of view, $x=640$\\
For the vertical field of view, $x=480$ \\
\\
When $f=50$, the horizontal field of view (in degrees) is as follows: 
\[
2arctan(\frac{640}{20 \cdot 50}) = 65.2385
\]
The vertical field of view (in degrees) is as follows:
\[
2arctan(\frac{480}{20 \cdot 50}) = 51.2820
\]
\\
When $f=100$, the horizontal field of view (in degrees) is as follows: 
\[
2arctan(\frac{640}{20 \cdot 100}) = 35.4893
\]
The vertical field of view (in degrees) is as follows:
\[
2arctan(\frac{480}{20 \cdot 100}) = 26.9915
\]

\newpage

\subsection{Part 2}

A rotation of $\theta$ about the y axis has the following form
\[ \left( \begin{array}{ccc}
cos(\theta) & 0 & sin(\theta) \\
0 & 1 & 0 \\
-sin(\theta) & 0 & cos(\theta) \end{array} \right)\]
For us, $\theta=-45$ degrees, and we need homogeneous coordinates, thus our matrix $R$ is the following
\[ \left( \begin{array}{cccc}
1/\sqrt{2} & 0 & -1/\sqrt{2} & 0 \\
0 & 1 & 0 & 0\\
1/\sqrt{2} & 0 & 1/\sqrt{2} & 0 \\
0 & 0 & 0 & 1 \end{array} \right)\]
Translating to the right by 1 is the same as moving by one unit along the positive x-axis, which has the following matrix T 
\[ \left( \begin{array}{cccc}
1 & 0 & 0 & 1 \\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \end{array} \right)\]
Since we are translating to the right after rotation, we have to apply the matrix $T$ in the new rotated coordinated system, thus to go from original world coordinate to final ones, you need to compute $RT$ which ends up being
\[ \left( \begin{array}{cccc}
1/\sqrt{2} & 0 & -1/\sqrt{2} & 1/\sqrt{2} \\
0 & 1 & 0 & 0\\
1/\sqrt{2} & 0 & 1/\sqrt{2} & 1/\sqrt{2} \\
0 & 0 & 0 & 1 \end{array} \right)\]
For $(1,1,1)$ in the world coordinate system, let $p$ be the homogenous version of the point, so 
\[
p=(1,1,1,1)^T
\]
In order to find its coordinates in the new system, we need to find a vector $x$ such that $RTx=p$ thus 
\[
x=(RT)^{-1} p
\] 
After computing $x$ it turns out the point in the new coordinate system is as follows
\[
(\sqrt{2} - 1, 1,0)
\]

\section{Problem 3}

Here is my calibrate.m function
\lstinputlisting[firstline=1, lastline=55]{calibrate.m}

\subsection{Part 1}

I used the following code to generate the data set and then test the calibrate function:
\lstinputlisting[firstline=1, lastline=85]{test_calibration.m}
All of the differences ended up being trivial and were likely due to floating point error, thus the function itself works very well. \\
\\
I then introduced noise as was done in the function. I used the noisy pixel locations and kept the original 3D locations to see what camera parameters were obtained. The original script used a noise factor of 0.01. I decided to also use 0.02 and 0.1 as noise factors to see what increasing noise does to the parameters. Here was my script:
\lstinputlisting[firstline=89, lastline=120]{test_calibration.m}

I then compared the parameters obtained using the output. In order from original $K$ matrix to the recovered K matrix as it gets noisier, here are the $K$ matrices:
\begin{verbatim}
   100     0    50
     0   100    50
     0     0     1

  100.0364    0.0014   49.9896
         0  100.0330   49.9683
         0         0    1.0000

  100.0540   -0.0030   49.9785
         0  100.0624   50.0167
         0         0    1.0000

   99.8103    0.0289   50.1466
         0   99.8229   50.5030
         0         0    1.0000
\end{verbatim}

As can be observed, the pixel magnification factors do start to vary as noise is increased but not by much. The pixel center location also starts to vary, but not by much. The skew factor however becomes non-zero suggesting that it appears there is skew in the lens when there is noise. 
\newpage
Doing the same thing but for the $R$ matrices, here are the rotation matrices obtained

\begin{verbatim}
    0.9998         0    0.0200
         0    1.0000         0
   -0.0200         0    0.9998

    0.9998    0.0000    0.0199
   -0.0000    1.0000   -0.0003
   -0.0199    0.0003    0.9998

    0.9998   -0.0000    0.0199
    0.0000    1.0000    0.0000
   -0.0199   -0.0000    0.9998

    0.9998    0.0002    0.0207
   -0.0002    1.0000    0.0033
   -0.0207   -0.0033    0.9998
\end{verbatim}
As can be observed, the rotation matrix does start to vary from the original but not by too much as the pixel locations get noisier. \\
\\
Lastly, I compared the camera location parameter t. Since it was a vector, I lined by the vectors obtained in order from left to right by amount of noise in test. This was the result:

\begin{verbatim}
   -0.2000   -0.1991   -0.1999   -0.1965
         0    0.0002    0.0014    0.0017
         0   -0.0008    0.0019   -0.0305
\end{verbatim} 

The camera location parameter obtained does start to increasingly vary as noise increases. Again though, the small amount of noise we introduced did not change it a whole lot. 

\subsection{Part 2}

This is the code I used to test it on image 1:
\lstinputlisting[firstline=1, lastline=21]{prob3part2.m}
I ended up getting the following error:
\begin{verbatim}
Warning: Matrix is singular, close to singular or badly scaled.
         Results may be inaccurate. RCOND = NaN. 
\end{verbatim}
This likely occurred because our surface has a uniform z value meaning there are many possible calibration matrices that could obtain our result. 

\end{document}








